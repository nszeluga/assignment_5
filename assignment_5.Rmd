---
title: "assignment_5"
author: "Nicole Szeluga"
date: "10/26/2020"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(knitr)
```

<br>

## Exercise 1. Tibble and Data Import (OPTIONAL)

Import data frames listed below into R and
[parse](https://r4ds.had.co.nz/data-import.html#parsing-a-vector) the
columns appropriately when needed. Watch out for the formating oddities
of each dataset. Print the results with
`kable()`.

<br>

#### 1.1 Create the following tibble manually, first using `tribble()` and then using `tibble()`. Print both results.

`tribble()`:

| a |   b | c       |
| -: | --: | :------ |
| 1 | 2.1 | apple   |
| 2 | 3.2 | orrange |

`tibble()`:

| a |   b | c       |
| -: | --: | :------ |
| 1 | 2.1 | apple   |
| 2 | 3.2 | orrange |

<br>

#### 1.2 Import `https://raw.githubusercontent.com/nt246/NTRES6940-data-science/master/datasets/dataset2.txt` into R. Change the column names into “Name”, “Weight”, “Price”.

| Name   | Weight | Price |
| :----- | -----: | ----: |
| apple  |      1 |   2.9 |
| orange |      2 |   4.9 |
| durian |     10 |  19.9 |

<br>

#### 1.3 Import `https://raw.githubusercontent.com/nt246/NTRES6940-data-science/master/datasets/dataset3.txt` into R. Watch out for the first few lines, missing values, separators, quotation marks, and deliminaters.

| Name   | Weight | Price |
| :----- | -----: | ----: |
| apple  |      1 |   2.9 |
| orange |      2 |    NA |
| durian |     NA |  19.9 |

<br>

#### 1.4 Import `https://raw.githubusercontent.com/nt246/NTRES6940-data-science/master/datasets/dataset4.txt` into R. Watch out for comments, units, and decimal marks (which are `,` in this case).

| Name   | Weight | Price |
| :----- | -----: | ----: |
| apple  |      1 |   2.9 |
| orange |      2 |   4.9 |
| durian |     10 |  19.9 |

<br>

#### 1.5 Import `https://raw.githubusercontent.com/nt246/NTRES6940-data-science/master/datasets/dataset5.txt` into R. Parse the columns properly. Write this imported and parsed data frame into a new csv file named `dataset5_new.csv` in your `problem_sets` folder.

| Name   | Expiration Date | Time     |
| :----- | :-------------- | :------- |
| apple  | 2018-09-26      | 01:00:00 |
| orange | 2018-10-02      | 13:00:00 |
| durian | 2018-10-21      | 11:00:00 |

<br>

## Exercise 2. Weather station

This dataset contains the weather and air quality data collected by a
weather station in Taiwan. It was obtained from the Environmental
Protection Administration, Executive Yuan, R.O.C.
(Taiwan).

<br>

#### 2.1 The text file `https://raw.githubusercontent.com/nt246/NTRES6940-data-science/master/datasets/2015y_Weather_Station_notes.txt` contains desciptions of different variables collected by the station. Import it into R and print it in a table as shown below.

```{r}
weather <-  read_delim(file ='https://raw.githubusercontent.com/nt246/NTRES6940-data-science/master/datasets/2015y_Weather_Station_notes.txt', '-', col_names = TRUE)
print(weather)

```




<br>

#### 2.2 Import `https://raw.githubusercontent.com/nt246/NTRES6940-data-science/master/datasets/2015y_Weather_Station.csv` into R. As you can see, this dataset is a classic example of untidy data: values of a variable (i.e. hour of the day) are stored as column names; variable names are stored in the `item` column. Clean this dataset up by turning it into a tidy format. Also, parse the `date` variable into date format and parse `hour` into time. Turn all invalid values into `NA` and turn `NR` in rainfall into `0`. Parse all values into numbers. Show the first 6 rows and 15 columns of this cleaned dataset, as shown below. (Hint: you don’t have to do these tasks in the given order.)

```{r}
weather_untidy <- read_csv("https://raw.githubusercontent.com/nt246/NTRES6940-data-science/master/datasets/2015y_Weather_Station.csv")
weather_untidy[1:6,1:15]

weather_tidy <- pivot_longer(weather_untidy, cols = 4:27, names_to = 'hour', values_to = 'value') %>% 
  mutate(value=ifelse(value == "NR", 0, value),
         value=parse_double(value), 
         hour=parse_time(hour, "%H")) %>% 
  pivot_wider(names_from = 'item', values_from= 'value')
  
weather_tidy[1:6,1:15] 
```

<br>

<br>

#### 2.3 Using this cleaned dataset, plot the daily variation in ambient temperature on September 25, 2015, as shown below.

```{r}
weather_tidy %>% 
  filter(date == '2015-9-25') %>% 
  ggplot(, mapping = aes(x=hour, y = AMB_TEMP)) +
  geom_line()
```


<br>

#### 2.4 Plot the daily average ambient temperature throughout the year with a **continuous line**, as shown below.

```{r}
weather_tidy %>% 
  group_by(date) %>% 
  summarise('AMB_TEMP' = mean(AMB_TEMP)) %>% 
  ggplot(, mapping = aes(x=date, y = AMB_TEMP))+
  geom_line()
  

```
 


<br>

#### 2.5 Plot the total rainfall per month in a bar chart, as shown below. (Hint: seperating date into three columns might be helpful.)

```{r}
weather_tidy %>% 
  separate(date, c("year","month","day"), sep = "-", remove = FALSE) %>% 
  group_by(month) %>% 
  summarise('MonthlyRainfall' = sum(RAINFALL, na.rm = TRUE)) %>% 
  ggplot(, mapping = aes(x=month, y=MonthlyRainfall))+
  geom_bar(stat = "identity")
```



<br>

#### 2.6 Plot the per hour variation in PM2.5 in the first week of September with a **continuous line**, as shown below. (Hint: uniting the date and hour and parsing the new variable might be helpful.)

```{r}
library(lubridate)

weather_tidy %>% 
  filter(date >= as.Date('2015-09-01')& date<= as.Date('2015-09-07')) %>% 
  unite(time, date, hour, sep = " ") %>% 
  mutate(time = ymd_hms(time)) %>% 
  ggplot() +
  geom_line(mapping = aes( x = time, y= PM2.5))
  
```


<br>

## Exercise 3: Titanic passengers

This dataset contains information about a subset of the passengers who
were aboard the Titanic when it sank in
1912.


```{r}
titanic<-read_csv("https://raw.githubusercontent.com/nt246/NTRES6940-data-science/master/datasets/Titanic.csv")
kable(head(titanic))
```



And here are descriptions of the variables in the
dataset


```{r}
notes<-read_csv("https://raw.githubusercontent.com/nt246/NTRES6940-data-science/master/datasets/Notes.csv")
kable(notes)
```


### Part 1.

**Answer the questions below** and use **figures or tables** to support
your answer. Choose the most appropriate type of figure or table for
each
question.

#### 3.1 According to Wikipedia, there was an estimated 2,224 passengers and crew onboard the Titanic when it sank. How many of them do we have information on in this dataset? How many of them survived and how many did not? What is the overall survival rate?


```{r}
total <- nrow(titanic)

survived <- titanic %>% 
  filter(Survived == "1") %>% 
  nrow()

dead<- titanic %>% 
  filter(Survived == "0") %>% 
  nrow()

survived/(survived+dead)
```

We have information on 891 passengers and out of that list, 342 survived and 549 died. This brings the survival rate to 38%
<br>

#### 3.2 How many passengers on the Titanic were males and how many were females? What do you find when you break it down by ticket class?

```{r}
male <- titanic %>% 
  filter(Sex == "male") %>% 
  nrow()

female <- titanic %>% 
  filter(Sex == "female") %>% 
  nrow()

titanic %>% 
  filter(Pclass == "1" & Sex == "male") %>% 
  nrow()

titanic %>% 
  filter(Pclass == "1" & Sex == "female") %>% 
  nrow()

titanic %>% 
  filter(Pclass == "2" & Sex == "male") %>% 
  nrow()

titanic %>% 
  filter(Pclass == "2" & Sex == "female") %>% 
  nrow()
  
titanic %>% 
  filter(Pclass == "3" & Sex == "male") %>% 
  nrow()

titanic %>% 
  filter(Pclass == "3" & Sex == "female") %>% 
  nrow()

```


577 passengers were male and 314 were female. Dividing this by class, there are 122 males and 94 females in 1st class. 108 males and 76 females in 2nd class, and 347 males and 144 females in 3rd class. 

<br>

#### 3.3 How many passengers of each sex survived and how many of them did not? What is the survival rate for passengers of each sex?

```{r}
survived_male <- titanic %>% 
  filter(Survived == "1" & Sex == "male") %>% 
  nrow()

dead_male <- titanic %>% 
  filter(Survived == "0" & Sex == "male") %>% 
  nrow()

survived_female <- titanic %>% 
  filter(Survived == "1" & Sex == "female") %>% 
  nrow()

dead_female <- titanic %>% 
  filter(Survived == "0" & Sex == "female") %>% 
  nrow()

survived_female/female
survived_male/male
```


109 males and 233 females survived. 468 males and 81 females died. The overall survival rate for each sex was 74% for females and 19% for males.

<br>

#### 3.4 How many passengers do we have age information for (including estimated age)? For how many is the age information missing? What is the age distribution for passengers whose age information is available?

```{r}
age_info <- titanic %>% 
  drop_na(Age) %>% 
  nrow()

total-age_info

hist(titanic$Age)
```


714 passengers have age information and 177 are missing information. For the most part, the age distribution is a bell curve. The highest between 20-30 years old. 

<br>

#### 3.5 Show the age distribution per ticket class, per sex. What do you find?

```{r}
ggplot(data = titanic, mapping = aes(x = Pclass, y = Age, color= Sex)) +
  geom_bar(stat = "identity", na.rm = TRUE, position = "dodge")
```


I do not see any trend. 

<br>

#### 3.6 What is the age distribution of passengers who survived vs. those who did not? What hypothesis can you come up with when comparing these two distributions?

``` r
## Write your code here
```

<span style="color:blue"> Write your response here
</span>

<br>

#### 3.7 In this dataset, the Fare variable does not represent the fare per person. Instead, each ticket number has a corresponding fare, and some passengers share one single ticket number. Therefore, the Fare variable is the total fare for a group of passengers sharing the same ticket number. Knowing this, calculate the average fare per person. (You don’t need to show a table or a figure for this question, just show the code for the calculation)

``` r
## Write your code here
```

<span style="color:blue"> Write your response here
</span>

<br>

#### 3.8 Show the distribution of the number of family members (including siblings, spouses, parents, and children) that each passenger was accompanied by. Were most passengers travelling solo or with family?

``` r
## Write your code here
```

<span style="color:blue"> Write your response here
</span>

<br>

#### 3.9 Which ticket class did most of the largest families get? And which ticket class has the lowest proportion of female passengers who travelled solo out of all the female passengers in that class?

``` r
## Write your code here
```

<span style="color:blue"> Write your response here
</span>

<br>

#### 3.10 Do the port of embarkation matter for the survival rates of passengers? Why might this be the case?

``` r
## Write your code here
```

<span style="color:blue"> Write your response here </span>

<br>

## Exercise 4. Camera data (OPTIONAL)

This dataset contains information on 1038 camera models. It was obtained
from the following website:
<https://perso.telecom-paristech.fr/eagan/class/igr204/>

<br>

#### 4.1 Import `https://raw.githubusercontent.com/nt246/NTRES6940-data-science/master/datasets/camera.csv` to R. You will see that the `Model` columns contains both the brand names and model names of cameras. Split this column into two, one with brand name, and the other with model name, as shown below. Print the first 6 rows of the new data frame. (Hint: check the merge argument in `separate()`)

| Brand | Model              | Release date | Max resolution | Low resolution | Effective pixels | Zoom wide (W) | Zoom tele (T) | Normal focus range | Macro focus range | Storage included | Weight (inc. batteries) | Dimensions | Price |
| :---- | :----------------- | -----------: | -------------: | -------------: | ---------------: | ------------: | ------------: | -----------------: | ----------------: | ---------------: | ----------------------: | ---------: | ----: |
| Agfa  | ePhoto 1280        |         1997 |           1024 |            640 |                0 |            38 |           114 |                 70 |                40 |                4 |                     420 |         95 |   179 |
| Agfa  | ePhoto 1680        |         1998 |           1280 |            640 |                1 |            38 |           114 |                 50 |                 0 |                4 |                     420 |        158 |   179 |
| Agfa  | ePhoto CL18        |         2000 |            640 |              0 |                0 |            45 |            45 |                  0 |                 0 |                2 |                       0 |          0 |   179 |
| Agfa  | ePhoto CL30        |         1999 |           1152 |            640 |                0 |            35 |            35 |                  0 |                 0 |                4 |                       0 |          0 |   269 |
| Agfa  | ePhoto CL30 Clik\! |         1999 |           1152 |            640 |                0 |            43 |            43 |                 50 |                 0 |               40 |                     300 |        128 |  1299 |
| Agfa  | ePhoto CL45        |         2001 |           1600 |            640 |                1 |            51 |            51 |                 50 |                20 |                8 |                     270 |        119 |   179 |

<br>

#### 4.2 Many model names start with a name for the product line, which is then followed by a name for the particular model. Select all Canon cameras, and further split the model names into product line names (in this case, they are either “Powershot” or “EOS”) and model names. Show the first 6 lines of this new data frame. (Hint: notice that there are more than one possible separators)

| Brand | Line      | Model | Release date | Max resolution | Low resolution | Effective pixels | Zoom wide (W) | Zoom tele (T) | Normal focus range | Macro focus range | Storage included | Weight (inc. batteries) | Dimensions | Price |
| :---- | :-------- | :---- | -----------: | -------------: | -------------: | ---------------: | ------------: | ------------: | -----------------: | ----------------: | ---------------: | ----------------------: | ---------: | ----: |
| Canon | PowerShot | 350   |         1997 |            640 |              0 |                0 |            42 |            42 |                 70 |                 3 |                2 |                     320 |         93 |   149 |
| Canon | PowerShot | 600   |         1996 |            832 |            640 |                0 |            50 |            50 |                 40 |                10 |                1 |                     460 |        160 |   139 |
| Canon | PowerShot | A10   |         2001 |           1280 |           1024 |                1 |            35 |           105 |                 76 |                16 |                8 |                     375 |        110 |   139 |
| Canon | PowerShot | A100  |         2002 |           1280 |           1024 |                1 |            39 |            39 |                 20 |                 5 |                8 |                     225 |        110 |   139 |
| Canon | PowerShot | A20   |         2001 |           1600 |           1024 |                1 |            35 |           105 |                 76 |                16 |                8 |                     375 |        110 |   139 |
| Canon | PowerShot | A200  |         2002 |           1600 |           1024 |                1 |            39 |            39 |                 20 |                 5 |                8 |                     225 |        110 |   139 |

<br>

#### 4.3 Explore the full dataset (and some subsetted ones if you are interested) on your own using **a variety of the skills** that you have learned in this class so far (i.e. data visualization, transformation, and exploration). Come up with **at least 3 interesting findings or potential hypotheses**.

<br>

###### 4.3.1

``` r
## Write your code here
```

<span style="color:blue"> Write your response here </span>

<br>

###### 4.3.2

``` r
## Write your code here
```

<span style="color:blue"> Write your response here </span>

<br>

###### 4.3.3

``` r
## Write your code here
```

<span style="color:blue"> Write your response here
</span>

<br>

###### Don’t hesitate to continue writing if you have more than 3 interesting findings.

<br>